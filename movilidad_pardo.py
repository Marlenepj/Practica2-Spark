# -*- coding: utf-8 -*-
"""Movilidad_Pardo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s5soXzPmJs38zxiXuZX8BqC1dcCdJexQ

# **Análisis de movilidad urbana con Spark**

Objetivo: aplicar los conceptos fundamentales de Spark (RDDs, DataFrames, transformaciones y acciones) para realizar un análisis distribuido de datos reales o semi-reales sobre movilidad urbana.

Con base en los archivos ques están disponibles de forma libre en la página de CDMX (https://datos.cdmx.gob.mx/group/movilidad), se realiza el análisis del cualquier archivo CSV que se descargue. Visualizando algunos datos filtrados y resumiendo algunos cuestionamientos.
"""

# Pardo Juárez Marlene
# Fecha: 2025-05

"""
Este notebook PySpark realiza un análisis distribuido de movilidad urbana, combinando registros de viajes (simulados) y datos de afluencia diaria por estación.

Preguntas de interés a responder:
1. ¿Cuáles son las rutas con mayor congestión?
2. ¿En qué horarios hay más viajes?
3. ¿Qué zonas tienen más entrada o salida de vehículos?

Requisitos:
- Archivo CSV de afluencia diaria por estación con el siguiente formato: "afluencia_datos.csv".
"""

#Requerido para trabajar con Spark
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, month, count, sum as _sum, desc, udf
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType

# 1. Inicializamos SparkSession
spark = SparkSession.builder \
    .appName("AnalisisMovilidadCDMX") \
    .master("local[*]") \
    .getOrCreate()

# 2. Definimos el esquemad de la afluencia
schema_afluencia = StructType([
    StructField("fecha", DateType(), True),
    StructField("anio", IntegerType(), True),
    StructField("mes", StringType(), True),
    StructField("linea", StringType(), True),
    StructField("estacion", StringType(), True),
    StructField("afluencia", IntegerType(), True)
])

#Dataframe para la lectura del archivo en CSV
af_df = spark.read.csv(
    "afluencia_datos.csv",
    header=True,
    schema=schema_afluencia
)

# Inspecionamos primerp
af_df.printSchema()
af_df.show(5)

# 3. Análisis con DataFrame API sobre afluencia

# Líneas con mayor congestión, para ello sumanos la afluencia por línea
enlinea = (
    af_df
    .groupBy("linea")
    .agg(_sum("afluencia").alias("total_afluencia"))
    .orderBy(desc("total_afluencia"))
)
enlinea.show(5)

# Sumar afluencia por mes
enmes = (
    af_df
    .groupBy("mes")
    .agg(_sum("afluencia").alias("total_afluencia"))
    .orderBy(desc("total_afluencia"))
)
enmes.show(12)

# 3.3 Estaciones más concurridas (top estaciones)
est_top = (
    af_df
    .groupBy("estacion")
    .agg(_sum("afluencia").alias("total_afluencia"))
    .orderBy(desc("total_afluencia"))
)
est_top.show(5)

# RDD, cuenta los días disponibles por estación
rdd = af_df.rdd.map(lambda r: (r.estacion, 1))
conteo_dias = rdd.reduceByKey(lambda a, b: a + b)

# Obtiene el top 5 de las estaciones con más días de registro
top_dias = conteo_dias.takeOrdered(5, key=lambda x: -x[1])
print("Top 5 estaciones por días registrados:", top_dias)

# UDF simple para categorizar estaciones por zonas (norte, sur, centro)
def categoria_estacion(nombre):
    nombre_lower = nombre.lower()
    if "norte" in nombre_lower:
        return "Norte"
    if "sur" in nombre_lower:
        return "Sur"
    return "Centro"

udf_categoria = udf(categoria_estacion, StringType())

af_zonas = af_df.withColumn("zona_urbana", udf_categoria(col("estacion")))

# Se agrega afluencia por zona urbana
af_zonas.groupBy("zona_urbana").agg(_sum("afluencia").alias("afluencia_zona")).show()

# Se exporta el resultado a un archivo CSV por grupos o datos separados
(
    enlinea.coalesce(1)
    .write.csv("datos_salida/lineas_congestion.csv", header=True)
)
(
    enmes.coalesce(1)
    .write.csv("datos_salida/meses_viajes.csv", header=True)
)
(
    est_top.limit(1)
    .select("estacion", "total_afluencia")
    .coalesce(1)
    .write.csv("datos_salida/top_estacion.csv", header=True)
)
(
    af_zonas
    .groupBy("zona_urbana")
    .agg(_sum("afluencia").alias("afluencia_zona"))
    .coalesce(1)
    .write.csv("datos_salida/afluencia_por_zona.csv", header=True)
)

"""Graficación de la afluencia total por línea."""

pdf = af_df.toPandas()
import matplotlib.pyplot as plt
resumen_lineas = pdf.groupby('linea')['afluencia'].sum().sort_values(ascending=False)
plt.figure()
resumen_lineas.plot(kind='bar')
plt.title('Afluencia total por línea')
plt.xlabel('Línea')
plt.ylabel('Total de afluencia')
plt.tight_layout()
plt.show()

